\newpage 									% DO NOT TOUCH!
\addcontentsline{toc}{chapter}{Attachments}	% DO NOT TOUCH!
\appendix 								 	% DO NOT TOUCH!

\chapter{CUDA Matrix Multiplication Benchmark Code}\label{Attachment:theory-CUDA-matrix-multiplication-code}
The full code for the matrix multiplication benchmark is shown in Listing~\ref{Listing:theory-CUDA-matrix-multiplication-full-code} (file \code{matrixMul.cu}).
\begin{lstlisting}[caption={Matrix multiplication benchmark code. Taken from Nvidia's samples located in the users home directory by default: \code{\$HOME/NVIDIA-samples/0\_Introduction/matrixMul/}.},label={Listing:theory-CUDA-matrix-multiplication-full-code},escapechar=@]
/**
* Copyright 1993-2015 NVIDIA Corporation.  All rights reserved.
*
* Please refer to the NVIDIA end user license agreement (EULA) associated
* with this source code for terms and conditions that govern your use of
* this software. Any use, reproduction, disclosure, or distribution of
* this software and related documentation outside the terms of the EULA
* is strictly prohibited.
*
*/

/**
* Matrix multiplication: C = A * B.
* Host code.
*
* This sample implements matrix multiplication which makes use of shared memory
* to ensure data reuse, the matrix multiplication is done using tiling
* approach. It has been written for clarity of exposition to illustrate various
* CUDA programming principles, not with the goal of providing the most
* performant generic kernel for matrix multiplication. See also: V. Volkov and
* J. Demmel, "Benchmarking GPUs to tune dense linear algebra," in Proc. 2008
* ACM/IEEE Conf. on Supercomputing (SC '08), Piscataway, NJ: IEEE Press, 2008,
* pp. Art. 31:1-11.
*/

// System includes
#include <assert.h>
#include <stdio.h>

// CUDA runtime
#include <cuda_runtime.h>

// Helper functions and utilities to work with CUDA
#include <helper_cuda.h>
#include <helper_functions.h>

template <int BLOCK_SIZE>
__global__ void MatrixMulCUDAGlobal(float *C, float *A, float *B, int wA, int wB) {
	// Each thread computes one element of C by accumulating results into Cvalue
	float Cvalue = 0;
	int row = blockIdx.y * blockDim.y + threadIdx.y;
	int col = blockIdx.x * blockDim.x + threadIdx.x;
	for( int i = 0; i < wA; ++i )
		Cvalue += A[row * wA + i] * B[i * wB + col];
	
	C[row * wB + col] = Cvalue;
}

/**
* Matrix multiplication (CUDA Kernel) on the device: C = A * B
* wA is A's width and wB is B's width
*/
template <int BLOCK_SIZE>
__global__ void MatrixMulCUDA(float *C, float *A, float *B, int wA, int wB) {
	// Block index
	int bx = blockIdx.x;
	int by = blockIdx.y;
	
	// Thread index
	int tx = threadIdx.x;
	int ty = threadIdx.y;
	
	// Index of the first sub-matrix of A processed by the block
	int aBegin = wA * BLOCK_SIZE * by;
	
	// Index of the last sub-matrix of A processed by the block
	int aEnd = aBegin + wA - 1;
	
	// Step size used to iterate through the sub-matrices of A
	int aStep = BLOCK_SIZE;
	
	// Index of the first sub-matrix of B processed by the block
	int bBegin = BLOCK_SIZE * bx;
	
	// Step size used to iterate through the sub-matrices of B
	int bStep = BLOCK_SIZE * wB;
	
	// Csub is used to store the element of the block sub-matrix
	// that is computed by the thread
	float Csub = 0;
	
	// Loop over all the sub-matrices of A and B
	// required to compute the block sub-matrix
	for (int a = aBegin, b = bBegin; a <= aEnd; a += aStep, b += bStep) {
		// Declaration of the shared memory array As used to
		// store the sub-matrix of A
		__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
		
		// Declaration of the shared memory array Bs used to
		// store the sub-matrix of B
		__shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];
		
		// Load the matrices from device memory
		// to shared memory; each thread loads
		// one element of each matrix
		As[ty][tx] = A[a + wA * ty + tx];
		Bs[ty][tx] = B[b + wB * ty + tx];
		
		// Synchronize to make sure the matrices are loaded
		__syncthreads();
		
		// Multiply the two matrices together;
		// each thread computes one element
		// of the block sub-matrix
		#pragma unroll@\label{Line:matrix-multiplication-pragma-unroll}@
		
		for (int k = 0; k < BLOCK_SIZE; ++k) {
			Csub += As[ty][k] * Bs[k][tx];
		}
		
		// Synchronize to make sure that the preceding
		// computation is done before loading two new
		// sub-matrices of A and B in the next iteration
		__syncthreads();
	}
	
	// Write the block sub-matrix to device memory;
	// each thread writes one element
	int c = wB * BLOCK_SIZE * by + BLOCK_SIZE * bx;
	C[c + wB * ty + tx] = Csub;
}

void ConstantInit(float *data, int size, float val) {
	for (int i = 0; i < size; ++i) {
		data[i] = val;
	}
}

/**
* Run a simple test of matrix multiplication using CUDA
*/
int MatrixMultiply(int argc, char **argv, int block_size, const dim3 &dimsA,
const dim3 &dimsB) {
	// Allocate host memory for matrices A and B
	unsigned int size_A = dimsA.x * dimsA.y;
	unsigned int mem_size_A = sizeof(float) * size_A;
	float *h_A;
	checkCudaErrors(cudaMallocHost((void **)&h_A, mem_size_A));
	unsigned int size_B = dimsB.x * dimsB.y;
	unsigned int mem_size_B = sizeof(float) * size_B;
	float *h_B;
	checkCudaErrors(cudaMallocHost((void **)&h_B, mem_size_B));
	cudaStream_t stream;
	
	// Initialize host memory
	const float valB = 0.01f;
	ConstantInit(h_A, size_A, 1.0f);
	ConstantInit(h_B, size_B, valB);
	
	// Allocate device memory
	float *d_A, *d_B, *d_C;
	
	// Allocate host matrix C
	dim3 dimsC(dimsB.x, dimsA.y, 1);
	unsigned int mem_size_C = dimsC.x * dimsC.y * sizeof(float);
	float *h_C;
	checkCudaErrors(cudaMallocHost((void **)&h_C, mem_size_C));
	
	if (h_C == NULL) {
		fprintf(stderr, "Failed to allocate host matrix C!\n");
		exit(EXIT_FAILURE);
	}
	
	checkCudaErrors(cudaMalloc(reinterpret_cast<void **>(&d_A), mem_size_A));
	checkCudaErrors(cudaMalloc(reinterpret_cast<void **>(&d_B), mem_size_B));
	checkCudaErrors(cudaMalloc(reinterpret_cast<void **>(&d_C), mem_size_C));
	// Allocate CUDA events that we'll use for timing
	cudaEvent_t start, stop;
	checkCudaErrors(cudaEventCreate(&start));
	checkCudaErrors(cudaEventCreate(&stop));
	
	checkCudaErrors(cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking));
	
	// copy host memory to device
	checkCudaErrors(
	cudaMemcpyAsync(d_A, h_A, mem_size_A, cudaMemcpyHostToDevice, stream));
	checkCudaErrors(
	cudaMemcpyAsync(d_B, h_B, mem_size_B, cudaMemcpyHostToDevice, stream));
	
	// Setup execution parameters
	dim3 threads(block_size, block_size);
	dim3 grid(dimsB.x / threads.x, dimsA.y / threads.y);
	
	// Create and start timer
	printf("Computing result using CUDA Kernel...\n");
	
	// Performs warmup operation using matrixMul CUDA kernel
	if (block_size == 16) {
		MatrixMulCUDA<16>
		<<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
	} else {
		MatrixMulCUDA<32>
		<<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
	}
	
	printf("done\n");
	checkCudaErrors(cudaStreamSynchronize(stream));
	
	// Record the start event
	checkCudaErrors(cudaEventRecord(start, stream));
	
	// Execute the kernel
	int nIter = 10;
	
	for (int j = 0; j < nIter; j++) {
		if (block_size == 16) {
			MatrixMulCUDA<16>
			<<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
		} else {
			MatrixMulCUDA<32>
			<<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
		}
	}
	
	// Record the stop event
	checkCudaErrors(cudaEventRecord(stop, stream));
	
	// Wait for the stop event to complete
	checkCudaErrors(cudaEventSynchronize(stop));
	
	float msecTotal = 0.0f;
	checkCudaErrors(cudaEventElapsedTime(&msecTotal, start, stop));
	
	// Compute and print the performance
	float msecPerMatrixMul = msecTotal / nIter;
	double flopsPerMatrixMul = 2.0 * static_cast<double>(dimsA.x) *
	static_cast<double>(dimsA.y) *
	static_cast<double>(dimsB.x);
	double gigaFlops =
	(flopsPerMatrixMul * 1.0e-9f) / (msecPerMatrixMul / 1000.0f);
	printf(
	"Performance= %.2f GFlop/s, Time= %.3f msec, Size= %.0f Ops,"
	" WorkgroupSize= %u threads/block\n",
	gigaFlops, msecPerMatrixMul, flopsPerMatrixMul, threads.x * threads.y);
	
	// Copy result from device to host
	checkCudaErrors(
	cudaMemcpyAsync(h_C, d_C, mem_size_C, cudaMemcpyDeviceToHost, stream));
	checkCudaErrors(cudaStreamSynchronize(stream));
	
	printf("Checking computed result for correctness: ");
	bool correct = true;
	
	// test relative error by the formula
	//     |<x, y>_cpu - <x,y>_gpu|/<|x|, |y|>  < eps
	double eps = 1.e-6;  // machine zero
	
	for (int i = 0; i < static_cast<int>(dimsC.x * dimsC.y); i++) {
		double abs_err = fabs(h_C[i] - (dimsA.x * valB));
		double dot_length = dimsA.x;
		double abs_val = fabs(h_C[i]);
		double rel_err = abs_err / abs_val / dot_length;
		
		if (rel_err > eps) {
			printf("Error! Matrix[%05d]=%.8f, ref=%.8f error term is > %E\n", i,
			h_C[i], dimsA.x * valB, eps);
			correct = false;
		}
	}
	
	printf("%s\n", correct ? "Result = PASS" : "Result = FAIL");
	
	// Clean up memory
	checkCudaErrors(cudaFreeHost(h_A));
	checkCudaErrors(cudaFreeHost(h_B));
	checkCudaErrors(cudaFreeHost(h_C));
	checkCudaErrors(cudaFree(d_A));
	checkCudaErrors(cudaFree(d_B));
	checkCudaErrors(cudaFree(d_C));
	checkCudaErrors(cudaEventDestroy(start));
	checkCudaErrors(cudaEventDestroy(stop));
	printf(
	"\nNOTE: The CUDA Samples are not meant for performance"
	"measurements. Results may vary when GPU Boost is enabled.\n");
	
	if (correct) {
		return EXIT_SUCCESS;
	} else {
		return EXIT_FAILURE;
	}
}

/**
* Program main
*/
int main(int argc, char **argv)
{
	printf("[Matrix Multiply Using CUDA] - Starting...\n");
	
	if (checkCmdLineFlag(argc, (const char **)argv, "help") ||
	checkCmdLineFlag(argc, (const char **)argv, "?")) {
		printf("Usage -device=n (n >= 0 for deviceID)\n");
		printf("      -wA=WidthA -hA=HeightA (Width x Height of Matrix A)\n");
		printf("      -wB=WidthB -hB=HeightB (Width x Height of Matrix B)\n");
		printf(
		"  Note: Outer matrix dimensions of A & B matrices"
		" must be equal.\n");
		
		exit(EXIT_SUCCESS);
	}
	
	// This will pick the best possible CUDA capable device, otherwise
	// override the device ID based on input provided at the command line
	int dev = findCudaDevice(argc, (const char **)argv);
	
	int block_size = 32;
	
	int mul = 10;
	
	dim3 dimsA(mul * block_size, mul * block_size, 1);
	dim3 dimsB(mul * block_size, mul * block_size, 1);
	
	// width of Matrix A
	if (checkCmdLineFlag(argc, (const char **)argv, "wA")) {
		dimsA.x = getCmdLineArgumentInt(argc, (const char **)argv, "wA");
	}
	
	// height of Matrix A
	if (checkCmdLineFlag(argc, (const char **)argv, "hA")) {
		dimsA.y = getCmdLineArgumentInt(argc, (const char **)argv, "hA");
	}
	
	// width of Matrix B
	if (checkCmdLineFlag(argc, (const char **)argv, "wB")) {
		dimsB.x = getCmdLineArgumentInt(argc, (const char **)argv, "wB");
	}
	
	// height of Matrix B
	if (checkCmdLineFlag(argc, (const char **)argv, "hB")) {
		dimsB.y = getCmdLineArgumentInt(argc, (const char **)argv, "hB");
	}
	
	if (dimsA.x != dimsB.y) {
		printf("Error: outer matrix dimensions must be equal. (%d != %d)\n",
		dimsA.x, dimsB.y);
		exit(EXIT_FAILURE);
	}
	
	printf("MatrixA(%d,%d), MatrixB(%d,%d)\n", dimsA.x, dimsA.y, dimsB.x,
	dimsB.y);
	
	int matrix_result = MatrixMultiply(argc, argv, block_size, dimsA, dimsB);
	
	exit(matrix_result);
}
\end{lstlisting}




\chapter{Decomposition Project Build Script Arguments}\label{Attachment:decomposition-project-build-script-parameters}
The \code{build} script arguments, i.e. the usage instructions are shown in Listing~\ref{Listing:decomposition-project-build-script-usage} (file \code{build}).
\begin{lstlisting}[language={},caption={Decomposition project's \code{build} script usage. Taken from the Decomposition project repository on GitLab\protect\footref{Footnote:decomposition-project-gitlab-url}.},label={Listing:decomposition-project-build-script-usage}]
	usage: $0 [options] [target ...]
	
	By default, the script does not select any target. Build targets available for
	selection are listed below. If the --install option is used, the Decomposition header
	files as well as the selected targets will be installed into the directory
	specified by the --prefix option.
	
	Targets:
	all             Special target which includes all other targets.
	benchmark      Compile the 'src/Benchmark' directory.
	tests           Compile unit tests in the 'src/UnitTests' directory.
	
	General options:
	--help                                Write this help list and exit.
	--verbose                             Enables verbose build.
	--install=yes/no                      Enables the installation of Decomposition files. '$INSTALL' by default.
	--prefix=PATH                         Prefix for the installation directory. '$HOME/.local' by default.
	
	Options affecting all targets:
	--offline-build=yes/no                Disables online updates during the build. '$OFFLINE_BUILD' by default.
	--build=Debug/Release                 Build type.
	--build-jobs=NUM                      Number of processes to be used for the build. It is set to the number of available CPU cores by default.
	--cmake=CMAKE                         Path to the cmake command. '$CMAKE' by default.
	--cmake-only=yes/no                   Run only the cmake command, don't actually build anything. '$CMAKE_ONLY' by default.
	--compiler=gcc/clang/icc              Selects the compiler to use. '$COMPILER' by default.
	--with-mpi=yes/no                     Enables MPI. '$WITH_MPI' by default (OpenMPI required).
	--with-cuda=yes/no                    Enables CUDA. '$WITH_CUDA' by default (CUDA Toolkit is required).
	--with-cuda-arch=all/auto/3.0/3.5/... Chooses CUDA architecture. '$WITH_CUDA_ARCH' by default.
	--with-openmp=yes/no                  Enables OpenMP. '$WITH_OPENMP' by default.
	--with-gmp=yes/no                     Enables the wrapper for GNU Multiple Precision Arithmetic Library. '$WITH_GMP' by default.
	
	Options for the 'tests' and 'matrix-tests' targets:
	--run-tests=yes/no                    Runs unit tests if they were compiled. '$RUN_TESTS' by default.
	--tests-jobs=NUM                      Number of processes to be used for the unit tests. It is $TEST_JOBS by default.
	--with-system-gtest=yes/no            Use GTest installed in the local system and do not download the latest version. '$WITH_SYSTEM_GTEST' by default.
\end{lstlisting}




\chapter{Crout Method Implementation for the CPU}\label{Attachment:crout-method-implementation-CPU}
The Crout method implementation for the CPU using matrices $ \mathbb{L} $ and $ \mathbb{U} $ is shown in Listing~\ref{Listing:crout-method-implementation-CPU-LU} and using matrix $ \mathbb{Z} $ in Listing~\ref{Listing:crout-method-implementation-CPU-Z}.
\begin{lstlisting}[language={},caption={Implementation of the Crout method on the CPU using matrices $ \mathbb{L} $ and $ \mathbb{U} $. All matrix and variable types are obtained from template arguments of the method. Taken from the Decomposition project repository on GitLab\protect\footref{Footnote:decomposition-project-gitlab-url}.},label={Listing:crout-method-implementation-CPU-LU}]
template< typename Matrix1, typename Matrix2, typename Matrix3 >
void CroutMethod::decompose( Matrix1& A, Matrix2& L, Matrix3& U )
{
	using RealType  = typename Matrix1::RealType;
	using IndexType = typename Matrix1::IndexType;
	
	IndexType num_rows = A.getRows();
	IndexType num_cols = A.getColumns();
	
	TNL_ASSERT_EQ( num_rows, num_cols, "Matrix A must be a square matrix!" );
	
	IndexType i, j, k;
	RealType sum = 0;
	
	for( j = 0; j < num_rows; ++j )	{
		for( i = j; i < num_rows; ++i ) {
			sum = 0;
			for( k = 0; k < j; ++k ) {
				sum = sum + L.getElement( i, k ) * U.getElement( k, j );
			}
		
			L.setElement( i, j, A.getElement( i, j ) - sum );
		}
		
		for( i = j; i < num_rows; ++i ) {
			TNL_ASSERT( L.getElement( j, j ) != 0, std::cerr << "L( " << i << ", " << j << " ) = 0. Cannot divide by 0." << std::endl );
			sum = 0;
			for( k = 0; k < j; ++k ) {
				sum = sum + L.getElement( j, k ) * U.getElement( k, i );
			}
		
			U.setElement( j, i, ( A.getElement( j, i ) - sum ) / L.getElement( j, j ) );
		}
	}	
}
\end{lstlisting}

\begin{lstlisting}[language={},caption={Implementation of the Crout method on the CPU using matrix $ \mathbb{Z} $. Taken from the Decomposition project repository on GitLab\protect\footref{Footnote:decomposition-project-gitlab-url}.},label={Listing:crout-method-implementation-CPU-Z}]
template< typename Matrix1, typename Matrix2 >
void CroutMethod::decompose( Matrix1& A, Matrix2& Z )
{
	using RealType  = typename Matrix1::RealType;
	using IndexType = typename Matrix1::IndexType;
	
	IndexType num_rows = A.getRows();
	IndexType num_cols = A.getColumns();
	
	TNL_ASSERT_EQ( num_rows, num_cols, "Matrix A must be a square matrix!" );
	
	IndexType i, j, k;
	RealType sum = 0;
	
	for( j = 0; j < num_rows; ++j )	{
		for( i = j; i < num_rows; ++i ) {
			sum = 0;
			for( k = 0; k < j; ++k ) {
				sum = sum + Z.getElement( i, k ) * Z.getElement( k, j );
			}
		
			Z.setElement( i, j, A.getElement( i, j ) - sum );
		}
		
		for( i = j; i < num_rows; ++i ) {
			if( j == i ) continue;
			
			TNL_ASSERT( Z.getElement( j, j ) != 0, std::cerr << "Z( " << j << ", " << j << " ) = 0. Cannot divide by 0." << std::endl );
			sum = 0;
			for( k = 0; k < j; ++k ) {
			sum = sum + Z.getElement( j, k ) * Z.getElement( k, i );
			}

			Z.setElement( j, i, ( A.getElement( j, i ) - sum ) / Z.getElement( j, j ) );
		}
	}
}
\end{lstlisting}




\chapter{Random Dense Matrix Generator Script}\label{Attachment:random-dense-matrix-generator}
The Python script used to generate random dense matrices that were later decomposed in the benchmark can be seen in Listing~\ref{Listing:random-dense-matrix-generator}.
\begin{lstlisting}[language=Python,caption={Python script for generating random dense matrices in the \emph{SuitSparse Matrix Collection} \cite{Davis2011} format. On line~\ref{Line:eliminate-zeros-from-dense-matrix} it can be seen that any zeros were incremented which was done to assure that the matrices produced would be both strongly regular and composed only of nonzero elements.},label={Listing:random-dense-matrix-generator},escapechar=@]
import numpy as np

num_mtx_files = 3
num_rows_cols_range = [2000, 5000]
elements_range = [-1000, 1000]

mtx_files = np.random.randint(low=num_rows_cols_range[0], high=num_rows_cols_range[1], size=num_mtx_files)

for num_rows_cols in mtx_files:
	dense_mtx_filename = f"Cejka{num_rows_cols}.mtx"
	
	header_lines = [
	"%%MatrixMarket matrix coordinate real general",
	"%----------------------------------------------------------------------------",
	"% Cejka Dense Matrix Collection, Lukas Cejka",
	"% Insert URL here",
	f"% name: Cejka/{dense_mtx_filename}",
	"% date: 2022",
	"% author: L. Cejka",
	"% kind: Random Dense Matrix",
	"%----------------------------------------------------------------------------",
	]
	header_lines = [line + "\n" for line in header_lines]
	
	mtx_info = f"{num_rows_cols} {num_rows_cols} {num_rows_cols*num_rows_cols}\n"
	
	rand_floats = np.random.uniform(low=elements_range[0], high=elements_range[1], size=(num_rows_cols*num_rows_cols))
	rand_floats = [flt+1 if flt == 0 else flt for flt in rand_floats] @\label{Line:eliminate-zeros-from-dense-matrix}@
	rand_floats = [str(flt) + "\n" for flt in rand_floats]
	
	
	with open(dense_mtx_filename, 'w') as f:
		f.writelines(header_lines)
		f.write(mtx_info)
		for col in range(1, num_rows_cols):
			for row in range(1, num_rows_cols):
				f.write(f"{row} {col} {rand_floats[(col-1)*num_rows_cols + row - 1]}")
\end{lstlisting}