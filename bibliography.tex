\clearpage  							   	 % DO NOT TOUCH!
\addcontentsline{toc}{chapter}{Bibliography} % DO NOT TOUCH!

\begin{thebibliography}{45}
	
	\bibitem{F4RUu4doMdeEMKXX}
	CUDA C++ Best Practices Guide. \textit{CUDA Toolkit Documentation} [online]. 2022. [Accessed 17 August 2022]. Retrieved from: https://docs.nvidia.com/cuda/pdf/CUDA\_C\_Best\_Practices\_Guide.pdf
	\bibitem{Davis2011}
	DAVIS, Timothy A. and HU, Yifan. The university of Florida sparse matrix collection. \textit{ACM Transactions on Mathematical Software} [online]. 2011. Vol. 38, no. 1p. 1-25. [Accessed 16 August 2022]. DOI 10.1145/2049662.2049663. Retrieved from: https://dl.acm.org/doi/10.1145/2049662.2049663
	\bibitem{VVJW5lCpZRWyg8xc}
	RCI Cluster Hardware. \textit{RCI Cluster} [online]. [Accessed 16 August 2022]. Retrieved from: https://login.rci.cvut.cz/wiki/hardware
	\bibitem{Cardoso2017}
	CARDOSO, João M.P., COUTINHO, José Gabriel F. and DINIZ, Pedro C. Source code transformations and optimizations. In : \textit{Embedded Computing for High Performance} [online]. Elsevier, 2017. p. 137-183. [Accessed 13 August 2022]. ISBN 9780128041895. Retrieved from: https://linkinghub.elsevier.com/retrieve/pii/B9780128041895000053
	\bibitem{Chow2015}
	CHOW, Edmond and PATEL, Aftab. Fine-Grained Parallel Incomplete LU Factorization. \textit{SIAM Journal on Scientific Computing} [online]. 2015. Vol. 37, no. 2p. C169-C193. [Accessed 10 August 2022]. DOI 10.1137/140968896. Retrieved from: http://epubs.siam.org/doi/10.1137/140968896
	\bibitem{Ednu6dyrkWKz1Bv2}
	Template Numerical Library. \textit{Template Numerical Library: version main:1fc23ee} [online]. [Accessed 30 July 2022]. Retrieved from: https://tnl-project.gitlab.io/tnl/
	\bibitem{Oberhuber20210210}
	OBERHUBER, Tomáš, KLINKOVSKÝ, Jakub and FUČÍK, Radek. TNL: NUMERICAL LIBRARY FOR MODERN PARALLEL ARCHITECTURES. \textit{Acta Polytechnica} [online]. 10 February 2021. Vol. 61, no. SIp. 122-134. [Accessed 30 July 2022]. DOI 10.14311/AP.2021.61.0122. Retrieved from: https://ojs.cvut.cz/ojs/index.php/ap/article/view/6075
	\bibitem{Lindfield2019}
	LINDFIELD, George and PENNY, John. Linear Equations and Eigensystems. In : \textit{Numerical Methods} [online]. Elsevier, 2019. p. 73-156. [Accessed 28 June 2022]. ISBN 9780128122563. Retrieved from: https://linkinghub.elsevier.com/retrieve/pii/B9780128122563000117
	\bibitem{bGKyYAv1kWXEoBzx}
	Crout matrix decomposition. \textit{Wikipedia: the free encyclopedia} [online]. 2001-. [Accessed 28 June 2022]. Retrieved from: https://en.wikipedia.org/wiki/Crout\_matrix\_decomposition
	\bibitem{TgtpOw7zCHo3ii0m}
	LU decomposition. \textit{Wikipedia: the free encyclopedia} [online]. 2001-. [Accessed 28 June 2022]. Retrieved from: https://en.wikipedia.org/wiki/LU\_decomposition
	\bibitem{rqjYYJkSwERYYbSy}
	VISMOR. 4.3 Crout-s LU Factorization. \textit{Vismor} [online]. [Accessed 28 June 2022]. Retrieved from: https://vismor.com/documents/network\_analysis/matrix\_algorithms/S4.SS3.php
	\bibitem{Press2007}
	PRESS, William H. \textit{Numerical recipes: the art of scientific computing}. 3rd ed. Cambridge : Cambridge University Press, 2007. ISBN 9780521880688.
	\bibitem{Hernandez2013429}
	HERNÁNDEZ, Moisés, GUERRERO, Ginés D., CECILIA, José M., GARCÍA, José M., INUGGI, Alberto, JBABDI, Saad, BEHRENS, Timothy E. J., SOTIROPOULOS, Stamatios N. and YACOUB, Essa. Accelerating Fibre Orientation Estimation from Diffusion Weighted Magnetic Resonance Imaging Using GPUs. \textit{PLoS ONE} [online]. 29 April 2013. Vol. 8, no. 4p. 2. [Accessed 20 May 2022]. DOI 10.1371/journal.pone.0061892. Retrieved from: https://dx.plos.org/10.1371/journal.pone.0061892
	\bibitem{Harris28January2013}
	HARRIS, Mark. Using Shared Memory in CUDA C/C++. \textit{Nvidia Developer: Technical Blog} [online]. [Accessed 25 June 2022]. Retrieved from: https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/
	\bibitem{McKennon13June2013}
	MCKENNON, Justin. CUDA Parallel Thread Management. \textit{Microway} [online]. [Accessed 23 June 2022]. Retrieved from: https://www.microway.com/hpc-tech-tips/cuda-parallel-thread-management/
	\bibitem{NvidiaJanuary2022}
	NVIDIA. CUDA Runtime API: API Reference Manual. \textit{Nvidia Docs} [online]. [Accessed 21 June 2022]. Retrieved from: https://docs.nvidia.com/cuda/pdf/CUDA\_Runtime\_API.pdf
	\bibitem{xUOrKLpxlGjvTonr}
	MARTÍNEZ, Manuel Ujaldón. CUDA Optimizations, Debugging and Profiling. \textit{Partnership for advanced computing in Europe} [online]. [Accessed 14 June 2022]. Retrieved from: http://materials.prace-ri.eu/35/1/gpuvideo4.pdf
	\bibitem{Brown18November2019}
	BROWN, Gordon. ComputeCpp v1.1.6: Changes to Work-item Mapping Optimization. \textit{Codeplay} [online]. [Accessed 14 June 2022]. Retrieved from: https://codeplay.com/portal/blogs/2019/11/18/computecpp-v1-1-6-changes-to-work-item-mapping-optimization.html
	\bibitem{Cabrera4December2019}
	CABRERA, Fang. The CUDA Parallel Programming Model - 5. Memory Coalescing. \textit{Fan Cabrera: A tech notebook} [online]. [Accessed 14 June 2022]. Retrieved from: https://nichijou.co/cuda5-coalesce/
	\bibitem{Harris7January2013}
	HARRIS, Mark. How to Access Global Memory Efficiently in CUDA C/C++ Kernels. \textit{Nvidia Developer: Technical Blog} [online]. [Accessed 14 June 2022]. Retrieved from: https://developer.nvidia.com/blog/how-access-global-memory-efficiently-cuda-c-kernels/
	\bibitem{Rose2017}
	ROSE, Chris. \textit{Cuda Succinctly}. United States : CreateSpace Independent Publishing Platform, 2017. ISBN 9781542827409.
	\bibitem{Hsiao17December2019}
	HSIAO, Yao. GPU: CUDA intro. \textit{Hack MD} [online]. [Accessed 11 June 2022]. Retrieved from: https://hackmd.io/@yaohsiaopid/ryHNKkxTr?type=view
	\bibitem{Ruetsch2008}
	RUETSCH, Greg and OSTER, Brent. Getting Started with CUDA. \textit{Nvidia} [online]. [Accessed 7 June 2022]. Retrieved from: https://www.nvidia.com/content/cudazone/download/Getting\_Started\_w\_CUDA\_Training\_NVISION08.pdf
	\bibitem{sk7jHd5INXJOAEUe}
	RENNICH, Steve and , Nvidia. CUDA C/C++ Streams and Concurrency. \textit{Nvidia Developer} [online]. [Accessed 7 June 2022]. Retrieved from: https://developer.download.nvidia.com/CUDA/training/StreamsAndConcurrencyWebinar.pdf
	\bibitem{AbiChahla18June2008}
	ABI-CHAHLA, Fedy. Nvidia's CUDA: The End of the CPU?. \textit{Tom's Hardware} [online]. [Accessed 5 June 2022]. Retrieved from: https://www.tomshardware.com/reviews/nvidia-cuda-gpu,1954.html
	\bibitem{Durant10May2017}
	DURANT, Luke, GIROUX, Olivier, HARRIS, Mark and STAM, Nick. Inside Volta: The World-s Most Advanced Data Center GPU. \textit{Nvidia Developer: Technical Blog} [online]. [Accessed 30 May 2022]. Retrieved from: https://developer.nvidia.com/blog/inside-volta/
	\bibitem{Marziale2010}
	MARZIALE, Lodovico, MOVVA, Santhi, RICHARD III, Golden G., ROUSSEV, Vassil and SCHWIEBERT, Loren. Massively Threaded Digital Forensics Tools. In : \textit{Handbook of Research on Computational Forensics, Digital Crime, and Investigation} [online]. IGI Global, 2010. p. 234-256. Advances in Digital Crime, Forensics, and Cyber Terrorism. [Accessed 30 May 2022]. ISBN 9781605668369. Retrieved from: http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-60566-836-9.ch010
	\bibitem{OsGyRFLMngy0j8Pv}
	, dogma1138. CUDA support much more languages than just C++ and Fortran. \textit{Hacker News} [online]. [Accessed 22 May 2022]. Retrieved from: https://news.ycombinator.com/item?id=26605219
	\bibitem{rfiOEXAGDlcAOxF3}
	, Nvidia. NVIDIA A100 TENSOR CORE GPU: Unprecedented acceleration at every scale. \textit{Nvidia} [online]. [Accessed 22 May 2022]. Retrieved from: https://www.nvidia.com/en-us/data-center/a100/
	\bibitem{May1December2020}
	MAY, Keith. NVIDIA GeForce RTX 3060 Ti Founders Edition Graphics Card Review. \textit{WCCFtech} [online]. [Accessed 22 May 2022]. Retrieved from: https://wccftech.com/review/nvidia-geforce-rtx-3060-ti-founders-edition-graphics-card-review/2/
	\bibitem{SMhyh0H3oh3nlda0}
	, TechPowerUp. NVIDIA GeForce RTX 3060. \textit{TechPowerUp} [online]. [Accessed 22 May 2022]. Retrieved from: https://www.techpowerup.com/gpu-specs/geforce-rtx-3060.c3682
	\bibitem{Smith18May2016}
	SMITH, Ryan. NVIDIA Posts Full GeForce GTX 1070 Specifications: 1920 CUDA Cores Boosting to 1.68GHz. \textit{AnandTech} [online]. [Accessed 22 May 2022]. Retrieved from: https://www.anandtech.com/show/10336/nvidia-posts-full-geforce-gtx-1070-specs
	\bibitem{jAnwkq6mMKYTLUOB}
	, TechPowerUp. NVIDIA GeForce GTX 1070. \textit{TechPowerUp} [online]. [Accessed 22 May 2022]. Retrieved from: https://www.techpowerup.com/gpu-specs/geforce-gtx-1070.c2840
	\bibitem{Walton7July2021}
	WALTON, Jarred. Nvidia GeForce RTX 3060 12GB Review: Hope Springs Eternal. \textit{Tom's HARDWARE} [online]. [Accessed 22 May 2022]. Retrieved from: https://www.tomshardware.com/reviews/nvidia-geforce-rtx-3060-review
	\bibitem{wGXr33zSUweXiQMY}
	, W1zzard. MSI GeForce RTX 3060 Gaming X Trio Review: The GeForce Ampere Architecture. \textit{TechPowerUp} [online]. [Accessed 22 May 2022]. Retrieved from: https://www.techpowerup.com/review/msi-geforce-rtx-3060-gaming-x-trio/2.html
	\bibitem{Hagedoorn6October2016}
	HAGEDOORN, Hilbert. Nvidia GeForce GTX 1070 review - Pascal GPU Architecture. \textit{The guru of 3D} [online]. [Accessed 22 May 2022]. Retrieved from: https://www.guru3d.com/articles-pages/nvidia-geforce-gtx-1070-review,3.html
	\bibitem{oaUUFoT7oI5ApIyY}
	, Nvidia. NVIDIA TURING GPU ARCHITECTURE: Graphics Reinvented. \textit{Nvidia} [online]. [Accessed 22 May 2022]. Retrieved from: https://images.nvidia.com/aem-dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf
	\bibitem{soj8qSRbfefUdi8Y}
	, Nvidia. NVIDIA A100 Tensor Core GPU Architecture: UNPRECEDENTED ACCELERATION AT EVERY SCALE. \textit{Nvidia} [online]. [Accessed 22 May 2022]. Retrieved from: https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf
	\bibitem{Oh10September2012}
	OH, Fred. What Is CUDA?. \textit{Nvidia Official Blog} [online]. [Accessed 20 May 2022]. Retrieved from: https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/
	\bibitem{NVIDIAMay2022}
	NVIDIA, Corporation. CUDA C++ Programming Guide. [online]. [Accessed 19 May 2022]. Retrieved from: https://docs.nvidia.com/cuda/pdf/CUDA\_C\_Programming\_Guide.pdf
	\bibitem{Glawion7March2022}
	GLAWION, Alex. Server vs. Desktop CPUs: What are the differences?. \textit{CG Director} [online]. [Accessed 19 May 2022]. Retrieved from: https://www.cgdirector.com/server-vs-desktop-cpus/
	\bibitem{Cejka2020}
	ČEJKA, Lukáš. \textit{Formats for storage of sparse matrices on GPU}. Bachelor's Degree Project. Prague, 2020.
	\bibitem{Anzt2019}
	ANZT, Hartwig, RIBIZEL, Tobias, FLEGAR, Goran, CHOW, Edmond and DONGARRA, Jack. ParILUT - A Parallel Threshold ILU for GPUs. In : \textit{2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)} [online]. IEEE, 2019. p. 231-241. [Accessed 3 May 2022]. ISBN 978-1-7281-1246-6. Retrieved from: https://ieeexplore.ieee.org/document/8820992/
	\bibitem{Sharma2019}
	SHARMA, Bharatkumar and HAN, Jaegeun. \textit{Learn CUDA Programming: A beginner's guide to GPU programming and parallel computing with CUDA 10.x and C/C++}. Birmingham : Packt Publishing, 2019. ISBN 978-1788996242.
	\bibitem{Saad2003}
	SAAD, Y. \textit{Iterative methods for sparse linear systems}. 2nd ed. Philadelphia : Society for Industrial and Applied Mathematics, 2003. ISBN 978-0898715347.
	
\end{thebibliography}